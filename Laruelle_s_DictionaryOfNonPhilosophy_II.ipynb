{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRANCOIS LARUELLE'S 'DICTIONARY OF NON-PHILOSOPHY' \n",
    "## Notebook2: \n",
    "## Extracting Citations of Mentioned Philosophers\n",
    "## By Moses Boudourides & Benjamin Pang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3179,
     "status": "error",
     "timestamp": 1571910651398,
     "user": {
      "displayName": "Nas Gopee",
      "photoUrl": "",
      "userId": "08967367925255446352"
     },
     "user_tz": -240
    },
    "id": "IK7KzXvzKgiS",
    "outputId": "700c2d83-4889-4008-f801-56f48fe03430"
   },
   "outputs": [],
   "source": [
    "import urllib, os, codecs, random, operator, re, string, copy, dateutil.parser, itertools, pickle, datetime, math, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from string import punctuation, digits\n",
    "import pathlib\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "import inflect\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community\n",
    "from networkx import NetworkXNoPath\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import pygraphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib._color_data as mcd\n",
    "import matplotlib.patches as mpatch\n",
    "from matplotlib import colors as mcolors\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "from IPython.core.display import display, HTML\n",
    "from string import Template\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "tableau_cl=[c[4:] for c in mcolors.TABLEAU_COLORS] #10 colors\n",
    "xkcd_cl=[c for c in list({name for name in mcd.CSS4_COLORS\n",
    "         if \"xkcd:\" + name in mcd.XKCD_COLORS}) if c!=\"navy\"] #48 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = '''\n",
    "<script src='https://cdnjs.cloudflare.com/ajax/libs/sigma.js/1.2.1/sigma.min.js'></script>\n",
    "<script src='https://cdnjs.cloudflare.com/ajax/libs/sigma.js/1.2.1/plugins/sigma.plugins.relativeSize.min.js'></script>\n",
    "<script>\n",
    "sigmas = {}\n",
    ";(function(undefined) {\n",
    "\n",
    "  sigma.canvas.labels.def = function(node, context, settings) {\n",
    "    var fontSize,\n",
    "        prefix = settings('prefix') || '',\n",
    "        size = node[prefix + 'size'],\n",
    "        labelWidth = 0,\n",
    "        labelPlacementX,\n",
    "        labelPlacementY,\n",
    "        alignment;\n",
    "\n",
    "    if (size < settings('labelThreshold'))\n",
    "      return;\n",
    "\n",
    "    if (typeof node.label !== 'string')\n",
    "      return;\n",
    "\n",
    "    if (settings('labelAlignment') === undefined){ \n",
    "      alignment = settings('defaultLabelAlignment');\n",
    "    } else {\n",
    "      alignment = settings('labelAlignment');\n",
    "    }\n",
    "\n",
    "    fontSize = (settings('labelSize') === 'fixed') ?\n",
    "      settings('defaultLabelSize') :\n",
    "      settings('labelSizeRatio') * size;\n",
    "\n",
    "    context.font = (settings('fontStyle') ? settings('fontStyle') + ' ' : '') +\n",
    "      fontSize + 'px ' + settings('font');\n",
    "    context.fillStyle = (settings('labelColor') === 'node') ?\n",
    "      (node.color || settings('defaultNodeColor')) :\n",
    "      settings('defaultLabelColor');\n",
    "\n",
    "    labelWidth = context.measureText(node.label).width;\n",
    "    labelPlacementX = Math.round(node[prefix + 'x'] + size + 3);\n",
    "    labelPlacementY = Math.round(node[prefix + 'y'] + fontSize / 3);\n",
    "\n",
    "    switch (alignment) {\n",
    "      case 'inside':\n",
    "        if (labelWidth <= size * 2){\n",
    "          labelPlacementX = Math.round(node[prefix + 'x'] - labelWidth / 2 );\n",
    "        }\n",
    "        break;\n",
    "      case 'center':\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] - labelWidth / 2 );\n",
    "        break;\n",
    "      case 'left':\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] - size - labelWidth - 3 );\n",
    "        break;\n",
    "      case 'right':\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] + size + 3);\n",
    "        break;\n",
    "      case 'top':\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] - labelWidth / 2 );\n",
    "        labelPlacementY = labelPlacementY - size - fontSize;\n",
    "        break;\n",
    "      case 'bottom':\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] - labelWidth / 2 );\n",
    "        labelPlacementY = labelPlacementY + size + fontSize;\n",
    "        break;\n",
    "      default:\n",
    "        // Default is aligned 'right'\n",
    "        labelPlacementX = Math.round(node[prefix + 'x'] + size + 3);\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    context.fillText(\n",
    "      node.label,\n",
    "      labelPlacementX,\n",
    "      labelPlacementY\n",
    "    );\n",
    "  };\n",
    "  \n",
    "}).call(this)\n",
    "</script>\n",
    "'''\n",
    "HTML(scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cF7BywMOKgiZ"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'laruelle_francois_dictionary_of_non-philosophy_CLEANED_V3.txt'\n",
    "titlename = \"Francois Laruelle's 'Dictionary of Non-Philosophy'\"\n",
    "\n",
    "f = codecs.open(filename, \"r\", encoding=\"utf-8\").readlines()\n",
    "\n",
    "num_lines = 0\n",
    "num_words = 0\n",
    "num_chars = 0\n",
    "for line in f:\n",
    "    words = line.split()\n",
    "    num_lines += 1\n",
    "    num_words += len(words)\n",
    "    num_chars += len(line)\n",
    "print(\"%s has number of words = %i (and number of characters/symbols = %i)\" %(titlename,num_words,num_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_d={}\n",
    "text=\"\\n\".join(f).split(\"#\")\n",
    "text=[s.replace('\\r','') for s in text if len(s)>0]\n",
    "for t in text:\n",
    "    tt=t.split('\\n')\n",
    "    tt=[s for s in tt if len(s)>0]\n",
    "    items_d[tt[0].strip().lower()]=' '.join(tt[1:]).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(items_d))\n",
    "sorted(items_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in items_d.items():\n",
    "    print(list(items_d.keys()).index(k)+1, '|', k, '|', v)\n",
    "    print(\"\\n &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\\n\".join(list(items_d.values()))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "nuw=len(words)\n",
    "uw=len(set(words))\n",
    "print(\"%s contains %i nonunique and %i unique words\"%(titlename,nuw,uw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "d_tags = {}\n",
    "\n",
    "docs_d={\"Dictionary of Non-Philosophy\":text}\n",
    "for key, value in docs_d.items():\n",
    "    arr = []\n",
    "    doc = nlp(value.replace('\\n',''))\n",
    "    #Keep these types of nlp entities\n",
    "    keep_l = ['PERSON'] #,'NORP','PRODUCT','ORG']\n",
    "    #Typo/model error + german corrections\n",
    "    drop_t = []\n",
    "    \n",
    "    #Things inflect library handles poorly or to exclude from touching\n",
    "    ex_ls = []\n",
    "    \n",
    "    for X in doc.ents:\n",
    "        s1 = X.text\n",
    "        if (X.label_ in keep_l) and (s1.lower() not in drop_t) and (s1):\n",
    "            arr.append((s1, X.label_))\n",
    "    d_tags[key] = arr\n",
    "# pprint(d_tags)\n",
    "names=[]\n",
    "for k,v in d_tags.items():\n",
    "    for vv in v:\n",
    "        if vv[0] not in names:\n",
    "            p=vv[0].replace(\"'\",\"\")\n",
    "            # p=p.title()\n",
    "            names.append(p)\n",
    "names=sorted(set(names))\n",
    "print(len(names))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rem=[]\n",
    "for p in names:\n",
    "    if \"_\" in p:\n",
    "        rem.append(p)\n",
    "    if \"--\" in p:\n",
    "        rem.append(p)\n",
    "    if p not in text:\n",
    "        rem.append(p)\n",
    "names=[p for p in names if p not in rem]\n",
    "pp=[q for q in itertools.product(names,names) if q[0]!=q[1]]\n",
    "for q in pp:\n",
    "    if q[0] in q[1]:\n",
    "        rem.append(q[0])\n",
    "    if q[1] in q[0]:\n",
    "        rem.append(q[1])\n",
    "    w=q[0]+\" \"+q[1]\n",
    "    if w in text:\n",
    "        names.append(w)\n",
    "        rem.append(q[0])\n",
    "        rem.append(q[1])\n",
    "names=[p for p in names if p not in rem]\n",
    "names=sorted(set(names))\n",
    "print(len(names))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rem=['a transcendental robinson', \n",
    " 'anthony paul smith', 'aletheia', 'amphibologies', 'anti-thetic', \n",
    "     'aphanisis', 'aporias', 'apriority', 'ariadne', 'au-monde', 'bachelardian', 'boredomk', \n",
    "     'catechresis', 'chora', 'chrisitan', 'dasein', 'de-biologization', 'de-hegelianized', \n",
    "     'diachrony', 'diffèrance', 'différance', 'différe(a)nce',\n",
    " 'ek-sistence', 'ekstases', 'erlebnis', 'es gibt das sein', 'essence', 'europanalysis',\n",
    " 'existingstranger',\n",
    " 'existingsubject',\n",
    " 'exteriorities', 'homothety', 'hyle',\n",
    " 'i.e. aporetic',\n",
    " 'immanence”–spinoza',\n",
    " 'inone', 'jean-louis destouches', 'jean-luc marion', 'kehre', 'klein)–but', \n",
    " 'm. gueroult',\n",
    " 'm. henry', 'mario bunge', 'marx-althusser', 'maurice pradines', 'max scheler', 'merleau-ponty’s', 'metadiscourses',\n",
    " 'metascience',\n",
    " 'metawhich',\n",
    " 'michel henry',\n",
    "     'non(-one',\n",
    " 'non-)truth',\n",
    " 'non-autopositional exteriority',\n",
    " 'non-spatializing',\n",
    " 'nonphilosopher',\n",
    " 'nonpsychoanalysis',\n",
    " 'occasionality',\n",
    " 'occasionnale',\n",
    " 'ousia',\n",
    " 'overman', 'philosophizable',\n",
    " 'physis', 'postmoderns',\n",
    " 'pragmaticist',\n",
    " 'primordial greece', 's. valdinoci', 'schellingian psychocosmism', 'scission', 'semicircularity of noesis',\n",
    " 'sid littlefield',\n",
    " 'subjectstranger', 'teuth', 'this transcendental opening',\n",
    " 'un autrui', 'wesen', 'whicht', 'y. heidegger', 'y. noema',\n",
    " 'y. noesis',\n",
    " 'y. nonphilosophy']\n",
    "names=[p for p in names if p not in rem]\n",
    "names=names+['robinson', 'bachelard', 'spinoza', 'destouches', 'marion', \n",
    "             'judaic diachronics', 'klein', 'gueroult', 'henry', 'bunge', 'marx', 'althusser', \n",
    "             'pradines', 'scheler', 'merleau-ponty', 'valdinoci', 'schelling', 'littlefield', 'smith', 'heidegger']\n",
    "names=sorted(set(names))\n",
    "print(len(names))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_dict={}\n",
    "for n in names:\n",
    "    if n in ['deleuze', 'deleuzian']:\n",
    "        alias_dict[n] = 'Deleuze'\n",
    "    elif n in ['derrida', 'derridian']:\n",
    "        alias_dict[n]='Derrida'\n",
    "    else:\n",
    "        alias_dict[n]=n\n",
    "        \n",
    "print(alias_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfreq=[]\n",
    "for i in names: \n",
    "    nfreq.append(text.count(i))\n",
    "pnf_df = pd.DataFrame(\n",
    "    {'Names': map(lambda x: x.title(), names), \n",
    "     'Frequency of Occurrences': nfreq\n",
    "    })\n",
    "pnf_df=pnf_df[['Names','Frequency of Occurrences']]\n",
    "pnf_df=pnf_df.sort_values(by ='Frequency of Occurrences',ascending=False)\n",
    "# trf_df=trf_df[trf_df[\"Frequency of Occurrences\"]>10]\n",
    "print(len(pnf_df))\n",
    "pnf_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=Counter()\n",
    "u=0\n",
    "for k,v in alias_dict.items():\n",
    "    print(k, v)\n",
    "    kval=pnf_df[pnf_df[\"Names\"]==k.title()]\n",
    "    try:\n",
    "        kkval=kval.at[u,'Frequency of Occurrences']\n",
    "        dd[v]+=int(kkval)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    u+=1\n",
    "afdf = pd.DataFrame(\n",
    "        {'Names': map(lambda x: x.title(), dd.keys()),\n",
    "         'Frequency of Occurrences': list(dd.values())\n",
    "        })\n",
    "afdf=afdf[['Names','Frequency of Occurrences']]\n",
    "afdf=afdf.sort_values(by ='Frequency of Occurrences',ascending=False)\n",
    "afdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afdf.Names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afdf.to_csv('Names_freqs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = afdf. to_records(index=False)\n",
    "records=sorted(records, key=lambda x: x[1],reverse=True)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for (i,j) in records if j>5] \n",
    "y_pos = range(len(keys)) #np.arange(len(keys))\n",
    "performance = [j for (i,j) in records if j>5]\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = plt.axes()\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.6) \n",
    "ax.invert_yaxis()\n",
    "plt.yticks(y_pos, keys)\n",
    "plt.xlabel('Frequency' )\n",
    "sst=\"Most cited philosophers in %s\" %titlename\n",
    "plt.title(sst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetd = pnf_df[['Names','Frequency of Occurrences']]\n",
    "tuplesd = [tuple(x) for x in subsetd.values]\n",
    "\n",
    "t=[]\n",
    "for (i,j) in tuplesd:\n",
    "    for k in range(j):\n",
    "#         print(i.replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "        t.append(i.replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "ttd=' '.join(t)\n",
    "\n",
    "wordcloud = WordCloud(collocations=False,background_color=\"white\",colormap=\"plasma\",width=4000,height=2000).generate(ttd)\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "default_colors = wordcloud.to_array()\n",
    "plt.imshow(default_colors, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "ss=\"Wordcloud of cited philosophers \\n in %s\" %titlename\n",
    "plt.suptitle(ss,fontsize=25)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1.3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_d={}\n",
    "text=\"\\n\".join(f).split(\"#\")\n",
    "text=[s.replace('\\r','') for s in text if len(s)>0]\n",
    "for t in text:\n",
    "    tt=t.split('\\n')\n",
    "    tt=[s for s in tt if len(s)>0]\n",
    "    items_d[tt[0].strip().lower()]=' '.join(tt[1:]).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neds = []\n",
    "\n",
    "for k, v in items_d.items():\n",
    "    for n, f in records:\n",
    "        if n.lower() in v:\n",
    "            neds.append((k, n))\n",
    "\n",
    "print(len(neds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges=[]\n",
    "for k,v in items_d.items():\n",
    "    for kk in items_d.keys():\n",
    "        if kk!=k:\n",
    "            if kk in v:\n",
    "                edges.append((k,kk))\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges += neds\n",
    "\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0=nx.DiGraph()\n",
    "G0.add_edges_from(edges)\n",
    "print(len(G0), len(G0.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=titlename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'other*': 'Other',\n",
    "    'rea*l essence': 'real essence',\n",
    "    'thought-worl*d': 'thought-world',\n",
    "    'transcendenta*l axiomatic': 'transcendental axiomatic',\n",
    "    'transcendenta*l science': 'transcendental science'\n",
    "}\n",
    "\n",
    "G = nx.relabel_nodes(G0, mapping)\n",
    "print(len(G.nodes()), len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnames = [n for n in G.nodes() if n.lower() in names]\n",
    "gnodes = [n for n in G.nodes() if n.lower() not in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsi=[100*math.log(1+G.in_degree(n)) for n in G.nodes()]\n",
    "nsi=[]\n",
    "for n in G.nodes():\n",
    "    if n in gnodes:\n",
    "        if G.in_degree(n)>0:\n",
    "            nsi.append(100*math.log(1+G.in_degree(n)))\n",
    "        else:\n",
    "            nsi.append(20)\n",
    "nsi1=[]\n",
    "for n in G.nodes():\n",
    "    if n in gnames:\n",
    "        if G.in_degree(n)>0:\n",
    "            nsi1.append(100*math.log(1+G.in_degree(n)))\n",
    "        else:\n",
    "            nsi1.append(20)\n",
    "figsize=(17,13)\n",
    "pos=graphviz_layout(G)\n",
    "\n",
    "def centroidnp(arr):\n",
    "    length = arr.shape[0]\n",
    "    return np.sum(arr[:, 0]) / length, np.sum(arr[:, 1]) / length\n",
    "    \n",
    "centroid = centroidnp(np.array([np.array(v) for k, v in pos.items() if k in gnodes]))\n",
    "\n",
    "upos = {}\n",
    "colors_data = {}\n",
    "\n",
    "dist = lambda a, b: ((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2) ** .5\n",
    "radmin = max(dist(v, centroid) for k, v in pos.items() if k in gnodes) * 2\n",
    "radmax = max(dist(v, centroid) for k, v in pos.items() if k in gnames)\n",
    "\n",
    "node_color=\"#ffb3b3\"\n",
    "node_color1=\"blue\"\n",
    "node_border_color=\"r\"\n",
    "edge_color=\"#668cff\"\n",
    "\n",
    "for k, v in pos.items():\n",
    "    x1 = v[0] - centroid[0]\n",
    "    y1 = v[1] - centroid[1]\n",
    "    d = dist(v, centroid)\n",
    "    theta = math.atan2(y1, x1)\n",
    "    scale = 1.5\n",
    "    scale1 = 2\n",
    "    if k in gnames and d < radmin:\n",
    "        upos[k] = (v[0] + math.cos(theta) * radmin * scale, v[1] + math.sin(theta) * radmin * scale)\n",
    "        colors_data[k] = node_color1\n",
    "    elif k in gnodes:\n",
    "        upos[k] = (v[0] + math.cos(theta) * d * scale1, v[1] + math.sin(theta) * d * scale1)\n",
    "        colors_data[k] = node_color\n",
    "    \n",
    "def adjust(a, t):\n",
    "    for i, p in t.items():\n",
    "        a[i] = a[i][0] + p[0], a[i][1] + p[1]\n",
    "\n",
    "tweaks = {\n",
    "    'universal noesis': (0, 5),\n",
    "    'performativity': (0, -10),\n",
    "    'transcendental axiomatic': (0, 10),\n",
    "    'non-psychoanalysis': (0, 10),\n",
    "    'europanalysis': (0, 20),\n",
    "    'time-without-temporality': (0, 10),\n",
    "    'force (of) thought': (-20, -10),\n",
    "    'given-without-givenness': (-10, 10),\n",
    "    'first name': (-40, -10),\n",
    "    'philosophical decision': (30, 30),\n",
    "    'radical immanence': (40, 0),\n",
    "    'stranger': (20, -10),\n",
    "    'real': (0, 50),\n",
    "    'thought': (0, 20),\n",
    "    'universal noesis': (0, 15),\n",
    "    'non-philosophy': (0, 15),\n",
    "    'material ontology': (30, 40),\n",
    "    'reversibility': (30, 20),\n",
    "    'experimentation': (-20, 20),\n",
    "    'non-intuitive': (0, -15),\n",
    "    'mystique': (60, 0),\n",
    "    'transcendental science': (0, -15),\n",
    "    'break': (20, -10),\n",
    "    'Husserl': (-20, 0),\n",
    "    'Quine': (0, -20),\n",
    "    'Plato': (0, 20),\n",
    "    'Plotinus': (0, -10),\n",
    "    'Sartre': (0, -20),\n",
    "    'Rousseau': (0, 20),\n",
    "    'Leibniz': (0, -20)\n",
    "}\n",
    "\n",
    "adjust(upos, tweaks)\n",
    "pos_data = upos\n",
    "\n",
    "plt.figure(figsize=figsize);\n",
    "g_nodes = nx.draw_networkx_nodes(G, upos, nodelist=gnodes, node_color=node_color,node_size=nsi)\n",
    "g_names = nx.draw_networkx_nodes(G, upos, nodelist=gnames, node_color=node_color1, node_shape='s',node_size=nsi1)\n",
    "g_nodes.set_edgecolor(node_border_color)\n",
    "nx.draw_networkx_edges(G, upos,arrowsize=12, edge_color=edge_color,alpha=0.3)\n",
    "# nx.draw_networkx_labels(G, pos)\n",
    "# nx.draw_networkx_edge_labels(G,pos,edge_labels=elabels);\n",
    "plt.axis('off');\n",
    "yoffset = {}\n",
    "y_off = -4 # offset on the y axis\n",
    "for k, v in upos.items():\n",
    "    yoffset[k] = (v[0], v[1]+y_off)\n",
    "nx.draw_networkx_labels(G, yoffset,font_size=13);\n",
    "sst=\"The directed graph of lexical items and cited philosophers \\n in %s\" %st\n",
    "plt.title(sst,fontsize=20)\n",
    "plt.margins(x=0.1, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = json_graph.node_link_data(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_template = Template('''\n",
    "sigmas.$order = new sigma({\n",
    "  renderer: {\n",
    "    container: 'container$order',\n",
    "    type: 'canvas'\n",
    "  },\n",
    "  settings: {\n",
    "    minArrowSize: 10,\n",
    "    labelThreshold: 1,\n",
    "    defaultLabelAlignment: 'bottom'\n",
    "  }\n",
    "})\n",
    "\n",
    "bind = S=>{\n",
    "  let graph = $graph_data\n",
    "  let pos = $pos_data\n",
    "  let colors = $node_colors\n",
    "\n",
    "  let get_neighbors = (id, g)=>{\n",
    "    let res = {}\n",
    "    g.nodes().map(n=>{\n",
    "      if(g.edges().find(e=> ~[e.source, e.target].indexOf(n.id) && ~[e.source, e.target].indexOf(id))){\n",
    "        res[n.id] = n\n",
    "      }\n",
    "    })\n",
    "    return res\n",
    "  }\n",
    "\n",
    "  graph.nodes.map((a, i)=>{\n",
    "    a.label = a.id\n",
    "    a.x = pos[a.id][0]\n",
    "    a.y = pos[a.id][1]\n",
    "    a.color = colors[a.id]\n",
    "    a.size = 1\n",
    "    S.graph.addNode(a)\n",
    "  })\n",
    "\n",
    "  graph.links.map((a, i)=>{\n",
    "    a.id = i\n",
    "    a.type = '$edge_type'\n",
    "    a.color = '$edge_color'\n",
    "    S.graph.addEdge(a)\n",
    "  })\n",
    "\n",
    "  S.bind('clickNode', e=>{\n",
    "    let id = e.data.node.id\n",
    "    let keep = get_neighbors(id, S.graph)\n",
    "    keep[id] = e.data.node\n",
    "  \n",
    "    S.graph.nodes().forEach(n=>{\n",
    "      n.color = keep[n.id] ? colors[n.id] : '#eee'\n",
    "    })\n",
    "  \n",
    "    S.graph.edges().forEach(e=>{\n",
    "      e.color = keep[e.source] && keep[e.target] ? '$edge_color' : 'rgba(238, 238, 238, .3)'\n",
    "    })\n",
    "  \n",
    "    S.refresh()\n",
    "  })\n",
    "\n",
    "  S.bind('clickStage', e=>{\n",
    "    if(!e.data.captor.isDragging){\n",
    "      S.graph.nodes().forEach(n=>{\n",
    "        n.color = colors[n.id]\n",
    "      })\n",
    "\n",
    "      S.graph.edges().forEach(e=>{\n",
    "        e.color = '$edge_color'\n",
    "      })\n",
    "\n",
    "      S.refresh()\n",
    "    }\n",
    "  })\n",
    "\n",
    "  sigma.plugins.relativeSize(S, 1)\n",
    "\n",
    "  S.refresh()\n",
    "}\n",
    "\n",
    "bind(sigmas.$order)\n",
    "''')\n",
    "\n",
    "def htor(h):\n",
    "    h = h.lstrip('#')\n",
    "    return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 'dir2'\n",
    "js_text = js_template.substitute({\n",
    "    'order': order,\n",
    "    'graph_data': json.dumps(graph_data),\n",
    "    'pos_data': json.dumps(upos),\n",
    "    'edge_type': 'arrow',\n",
    "    'node_colors': json.dumps(colors_data),\n",
    "    'edge_color': 'rgba(%d, %d, %d, .5)' % htor(edge_color)\n",
    "})\n",
    "\n",
    "html_template = Template('''\n",
    "<h1 style='font-family:sans-serif;text-align:center'>$title</h1>\n",
    "<br>\n",
    "<div id='container$order' style='height:800px'></div>\n",
    "<script>$js_text</script>\n",
    "''')\n",
    "\n",
    "html_text = html_template.substitute({\n",
    "    'order': order,\n",
    "    'title': sst,\n",
    "    'js_text': js_text\n",
    "})\n",
    "\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('graph%s.html' % order, 'w+')\n",
    "f.write(scripts + html_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_KeywordGraphCommunitiesClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
